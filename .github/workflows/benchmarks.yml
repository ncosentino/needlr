name: Benchmarks

on:
  # Manual trigger
  workflow_dispatch:
  # Weekly on Sunday at 3am UTC
  schedule:
    - cron: '0 3 * * 0'

env:
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: 1

jobs:
  check-changes:
    runs-on: ubuntu-latest
    outputs:
      has_changes: ${{ steps.check.outputs.has_changes }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check for changes since last benchmark
        id: check
        run: |
          # Fetch gh-pages branch if it exists
          git fetch origin gh-pages:gh-pages 2>/dev/null || true
          
          # Try to get last benchmarked commit
          LAST_COMMIT=$(git show gh-pages:.last-benchmark-commit 2>/dev/null || echo "")
          
          echo "Last benchmarked commit: $LAST_COMMIT"
          echo "Current commit: ${{ github.sha }}"
          
          # For manual trigger, always run
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual trigger - running benchmarks"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          elif [ -z "$LAST_COMMIT" ]; then
            echo "No previous benchmark found - running benchmarks"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          elif [ "$LAST_COMMIT" = "${{ github.sha }}" ]; then
            echo "No changes since last benchmark - skipping"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected - running benchmarks"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

  run-benchmarks:
    needs: check-changes
    if: needs.check-changes.outputs.has_changes == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 10.0.x

      - name: Restore
        run: dotnet restore src/NexusLabs.Needlr.Benchmarks/NexusLabs.Needlr.Benchmarks.csproj

      - name: Build Benchmarks
        run: dotnet build src/NexusLabs.Needlr.Benchmarks/NexusLabs.Needlr.Benchmarks.csproj -c Release --no-restore

      - name: Run Benchmarks
        run: |
          cd src/NexusLabs.Needlr.Benchmarks
          dotnet run -c Release --no-build -- \
            --filter '*' \
            --exporters json markdown html \
            --artifacts ../../benchmark-results

      - name: Prepare Benchmark JSON for Web
        run: |
          # BenchmarkDotNet creates one JSON file per benchmark class.
          # We need to merge all results into a single combined file.
          # Use jq to merge all Benchmarks arrays from all report files.
          
          cd benchmark-results
          
          # Find all full-compressed JSON files and merge their Benchmarks arrays
          JSON_FILES=$(find . -name '*-report-full-compressed.json' -type f)
          
          if [ -n "$JSON_FILES" ]; then
            # Create merged JSON with all benchmarks
            echo "$JSON_FILES" | xargs cat | jq -s '{
              Title: "Needlr Benchmarks",
              HostEnvironmentInfo: .[0].HostEnvironmentInfo,
              Benchmarks: [.[].Benchmarks[]]
            }' > results.json
          else
            echo '{"Benchmarks":[]}' > results.json
          fi
          
          cd ..

      - name: Extract Benchmark Descriptions
        run: |
          # Extract XML docs and baseline method from benchmark classes to create descriptions.json
          # This allows the web page to show descriptions and identify baselines without hardcoding
          
          BENCHMARK_DIR="src/NexusLabs.Needlr.Benchmarks/Benchmarks"
          OUTPUT_FILE="benchmark-results/descriptions.json"
          
          echo '{' > "$OUTPUT_FILE"
          first=true
          
          for file in "$BENCHMARK_DIR"/*.cs; do
            if [ -f "$file" ]; then
              # Get class name from filename
              classname=$(basename "$file" .cs)
              
              # Extract XML summary using grep/sed
              summary=$(grep -A 20 '/// <summary>' "$file" | grep -B 20 '/// </summary>' | head -20 | grep '///' | sed 's/.*\/\/\/ //' | sed 's/<[^>]*>//g' | tr '\n' ' ' | sed 's/  */ /g' | sed 's/^ *//' | sed 's/ *$//')
              
              # Extract the baseline method name (method with Baseline = true)
              baseline=$(grep -B 1 'public.*(' "$file" | grep -A 1 'Benchmark(Baseline = true)' | grep 'public' | sed 's/.*public[^a-zA-Z]*[a-zA-Z<>]*[[:space:]]\+\([a-zA-Z_][a-zA-Z0-9_]*\).*/\1/' | head -1)
              
              # Get relative path for source link
              relpath="src/NexusLabs.Needlr.Benchmarks/Benchmarks/$(basename "$file")"
              
              if [ "$first" = true ]; then
                first=false
              else
                echo ',' >> "$OUTPUT_FILE"
              fi
              
              # Escape quotes in summary
              summary_escaped=$(echo "$summary" | sed 's/"/\\"/g')
              
              echo "  \"$classname\": {\"description\": \"$summary_escaped\", \"source\": \"$relpath\", \"baseline\": \"$baseline\"}" >> "$OUTPUT_FILE"
            fi
          done
          
          echo '}' >> "$OUTPUT_FILE"
          
          echo "Generated descriptions.json:"
          cat "$OUTPUT_FILE"

      - name: Upload Benchmark Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results/

      - name: Setup Python for MkDocs
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install MkDocs
        run: pip install "mkdocs>=1.5,<2.0" mkdocs-material

      - name: Generate Articles Page
        run: python scripts/generate-articles.py docs/articles.md

      - name: Build Documentation
        run: python -m mkdocs build

      - name: Prepare Benchmark Results for Pages
        run: |
          # Create benchmarks directory in site
          mkdir -p site/benchmarks/results
          
          # Copy all benchmark results including JSON files for the web page
          cp -r benchmark-results/* site/benchmarks/ 2>/dev/null || true
          cp benchmark-results/results.json site/benchmarks/results/results.json 2>/dev/null || true
          cp benchmark-results/descriptions.json site/benchmarks/results/descriptions.json 2>/dev/null || true

      - name: Save Last Benchmark Commit
        run: echo "${{ github.sha }}" > site/.last-benchmark-commit

      - name: Publish to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
          keep_files: true
